A novel automatic segmentation of healthy and diseased retinal layers from OCT scans
This paper introduces a novel framework for segmenting retinal layers from optical coherence tomography (OCT) images. In order to account for the noise and inhomogeneity of OCT scans, especially for diseased ones, the proposed framework is based on unique joint model that combines shape, intensity, and spatial information, and is able to segment 12 distinct retinal layers. First, the shape prior is built using a subset of co-aligned training OCT images. The alignment process is initialized using an innovative method that employs multi-resolution edge tracking which defines control points on the tracked retinal boundaries. The shape model is then adapted during the segmentation process using visual appearance characteristics that are described using pixel-wise image intensities and their spatial interaction features. In order to more accurately model the empirical grey level distribution of OCT images, a linear combination of discrete Gaussians (LCDG) is used that has positive and negative components. Also, in order to accurately account for noise, the model is integrated with a second-order Markov Gibbs random field (MGRF) spatial interaction model. The proposed approach was tested on 200 normal and diseased OCT scans (e.g. Age macular degeneration (AMD), diabetic retinopathy), having their ground truth delineated by retina specialists, then measured using the Dice similarity coefficient (DSC), agreement coefficient (AC1), and average deviation (AD) metrics. The accuracy achieved by the segmentation approach clearly demonstrates the promise it holds for robust segmentation of retinal layers which would aid in the early diagnosis of different retinal abnormalities.
